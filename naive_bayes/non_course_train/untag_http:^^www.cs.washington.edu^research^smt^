


Simultaneous Multithreading home page





Simultaneous Multithreading Project




Overview
People
Publications







 Overview
The crucial problem facing today's high-speed microprocessors is maintaining 
high processor utilization in the face of long instruction and memory 
latencies. To 
alleviate this problem, modern processors issue multiple instructions per 
cycle (i.e., superscalars), or interleave the execution of different
threads in different cycles (multithreaded processors). Ultimately, though, 
both techniques are limited by the amount of parallelism available within a 
single thread in a single cycle.

 Simultaneous multithreading (SMT) is a technique that permits multiple 
independent threads to issue instructions to a superscalar's functional 
units in a single cycle. SMT combines the multiple-instruction-issue
features of wide superscalar processors with the latency-hiding ability
of multithreaded architectures.  On an SMT processor, all hardware contexts
are active simultaneously, competing each cycle for all available resources.
This dynamic sharing of processor resources enables SMT to exploit
thread-level and instruction-level parallelism interchangeably; both forms
of parallelism can be effectively used to increase processor utilization.

Our studies have
demonstrated that simultaneous multithreading significantly improves
processor throughput and performance on both multiprogrammed and parallel
workloads.  We have shown that these performance gains can be achieved
in an architecture with only minimal extensions to modern out-of-order
superscalar processors.

Our current and future work includes investigations of fast synchronization
techniques enabled by SMT.  We are also conducting research in other
architectural and compiler issues for simultaneous multithreading.




 People


Faculty
 Susan Eggers
 Hank Levy
Graduate students
 Jack Lo
 Dean Tullsen
Industrial collaborators (Digital Equipment Corporation)
 Joel S. Emer
 Rebecca L. Stamm






 Publications


 Converting Thread-Level Parallelism Into Instruction-Level Parallelism via Simultaneous Multithreading (Abstract, Postscript) 

J.L. Lo,
S.J. Eggers, 
J.S. Emer, 
H.M. Levy,
R.L. Stamm, and
D.M. Tullsen
 
Submitted for publication, July 1996.



 Exploiting Choice: Instruction Fetch and Issue on an Implementable Simultaneous Multithreading Processor (Abstract, Postscript) 

D.M. Tullsen,
S.J. Eggers, 
J.S. Emer, 
H.M. Levy,
J.L. Lo,
and R.L. Stamm
 
Proceedings of the 23rd Annual International Symposium on Computer Architecture, Philadelphia, PA, May 1996.



 Compilation Issues for a Simultaneous Multithreading Processor 
(Postscript) 

J.L. Lo, 
S.J. Eggers, 
H.M. Levy, and
D.M. Tullsen 
Proceedings of the First SUIF Compiler Workshop, Stanford, CA, January 1996, p. 146-7.



 Simultaneous Multithreading: Maximizing On-Chip Parallelism (Abstract, Postscript) 

D.M. Tullsen,
S.J. Eggers, and
H.M. Levy,
 Proceedings of the 22rd Annual International Symposium on Computer Architecture, Santa Margherita Ligure, Italy, June 1995.







 UW students:
Check the list of research projects still to do
on the student-affairs page.





This page maintained by Jack Lo

jlo@cs.washington.edu  


